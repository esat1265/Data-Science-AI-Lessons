{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4cd0fc12",
   "metadata": {},
   "source": [
    "# NLP- Naturel Language Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0819e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "!pip install textblob\n",
    "from textblob import TextBlob, Word\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "%matplotlib inline\n",
    "\n",
    "import re\n",
    "import nltk\n",
    "\n",
    "from nltk import word_tokenize, pos_tag\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\", UserWarning)\n",
    "warnings.simplefilter(\"ignore\", FutureWarning)\n",
    "warnings.simplefilter(\"ignore\", DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "824c2453",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Comment\"]=df[\"Comment\"].str.lower() #kucuk harfe cevir\n",
    "df[\"Comment\"]=df[\"Comment\"].str.replace(\"[^\\w\\s]\",\"\") #noktalama işaretlerini kaldır\n",
    "df[\"Comment\"]=df[\"Comment\"].str.replace(\"\\d+\",\"\") #d digit rakamları kaldır\n",
    "df[\"Comment\"]=df[\"Comment\"].str.replace(\"\\n\",\" \") #Satır sonu,\\n \n",
    "df[\"Comment\"]=df[\"Comment\"].str.replace(\"\\r\",\"\") #enter a basılmışsa \\r\n",
    "df[\"Comment\"]=df[\"Comment\"].str.replace(\"\\t\",\"\")\n",
    "df[\"Comment\"]=df[\"Comment\"].str.strip() #satır başında boşlukları kaldır "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7756e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Date\"]=pd.to_datetime(df[\"Date\"])\n",
    "\n",
    "df[\"Day\"]=df[\"Date\"].dt.dayofweek\n",
    "df[\"Month\"]=df[\"Date\"].dt.month\n",
    "df[\"Year\"]=df[\"Date\"].dt.year\n",
    "\n",
    "\n",
    "df['WeekDay']=df['Date'].dt.day_name()\n",
    "df['Month_Name']=df['Date'].dt.month_name()\n",
    "\n",
    "df.drop(\"Date\",axis=1,inplace=True)\n",
    "# Tarih donusumleri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5598baa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "df[['polarity','subjectivity']]=df['text'].apply(lambda t:pd.Series(TextBlob(t).sentiment))\n",
    "# Kelimelerin polaritysini buluyoruz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9daee345",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download(\"stopwords\")\n",
    "stop_word_list=nltk.corpus.stopwords.words(\"turkish\")\n",
    "# Gereksiz kelimeleri cikarma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8339c85a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "def wc(data,bgcolor):\n",
    "    from PIL import Image\n",
    "    mask = np.array(Image.open(\"cloud.png\"))\n",
    "    wc=WordCloud(background_color=bgcolor, width=800, height=400,mask=mask,max_words=100).generate(' '.join(data))\n",
    "    plt.figure( figsize=(20,10) )\n",
    "    plt.imshow(wc)\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae9399cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "wc(df[\"title\"],'white')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "920e8b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62c1b14f",
   "metadata": {},
   "outputs": [],
   "source": [
    "b=MultinomialNB()\n",
    "model=b.fit(x_train_dtm,y_train)\n",
    "b_predict=b.predict(x_test_dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a176f047",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_test,b_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d7bac43",
   "metadata": {},
   "source": [
    "# Sentiment Analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a010d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca77e238",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['subjectivity']>0.5,'sentiment']=\"pozitive\"\n",
    "df.loc[df['subjectivity']==0.5,'sentiment']=\"neutral\"\n",
    "df.loc[df['subjectivity']<0.5,'sentiment']=\"negative\"\n",
    "df\n",
    "# 0.05 ebsulon komsulugunda olanlara gore sinifladik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdfe6a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y=df['Comment'],df['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d19d309",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test=train_test_split(x,y,random_state=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e9286c",
   "metadata": {},
   "outputs": [],
   "source": [
    "vect=CountVectorizer()\n",
    "x_train_dtm=vect.fit_transform(x_train,y_train)\n",
    "x_test_dtm=vect.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65463d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_dtm.shape,x_test_dtm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b48a878",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_test(vect,x,y):\n",
    "    from sklearn.naive_bayes import GaussianNB\n",
    "    from sklearn.naive_bayes import BernoulliNB\n",
    "    from sklearn.svm import SVC\n",
    "    from sklearn.neighbors import KNeighborsClassifier\n",
    "    from sklearn.tree import DecisionTreeClassifier\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    from xgboost import XGBClassifier #yüklemek için !pip install xgboost kullandım\n",
    "    \n",
    "    from sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score\n",
    "    from sklearn.metrics import confusion_matrix,classification_report\n",
    "    \n",
    "    x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=60)\n",
    "    \n",
    "    print(x_train.shape,x_test.shape,y_train.shape,y_test.shape)\n",
    "    \n",
    "    g=GaussianNB()\n",
    "    b=BernoulliNB()\n",
    "    SVC=SVC()\n",
    "    KN=KNeighborsClassifier()\n",
    "    D=DecisionTreeClassifier()\n",
    "    R=RandomForestClassifier()\n",
    "    Log=LogisticRegression()\n",
    "    XGBC=XGBClassifier()\n",
    "    \n",
    "    algos=[g,b,SVC,KN,D,R,Log,XGBC]\n",
    "    algo_names=['GaussianNB','BernoulliNB','SVC','KNeighborsClassifier','DecisionTreeClassifier','RandomForestClassifier','LogisticRegression','XGBClassifier']   \n",
    "    \n",
    "    accuracy_scored=[]    \n",
    "        \n",
    "    x_train_dtm=vect.fit_transform(x_train).toarray()\n",
    "    x_test_dtm=vect.transform(x_test).toarray()\n",
    "    \n",
    "    for item in algos:\n",
    "        item.fit(x_train_dtm,y_train)\n",
    "        accuracy_scored.append(accuracy_score(y_test,item.predict(x_test_dtm)))\n",
    "    result=pd.DataFrame(accuracy_scored,columns=['accuracy_score'],index=algo_names)\n",
    "    result.accuracy_score=accuracy_scored\n",
    "    return result.sort_values('accuracy_score',ascending=False)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f75b411",
   "metadata": {},
   "outputs": [],
   "source": [
    "vect=CountVectorizer()\n",
    "tokenize_test(vect,x,y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
